{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from train_configurations import (regnet_y_400mf, tracknet_v2, tracknet_v2_2f,\n",
    "                                  tracknet_v2_4f, tracknet_v2_6f,\n",
    "                                  tracknet_v2_rnn, tracknet_v2_rnn_scheduler)\n",
    "\n",
    "from train_configurations.utils import get_standard_test_dataset\n",
    "from detection.testing import _get_checkpoint_filename, _get_results_folder\n",
    "\n",
    "# figures_folder = 'figures'\n",
    "figures_folder = '../TFM/pictures'\n",
    "\n",
    "if not os.path.exists(figures_folder):\n",
    "    os.makedirs(figures_folder)\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples for training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization of input frames and heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from the desired train configuration\n",
    "dataset = get_standard_test_dataset(tracknet_v2, 'prova')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute heatmap for an example frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_element = 15\n",
    "\n",
    "with torch.no_grad():\n",
    "    frames, heatmap = dataset[dataset_element]\n",
    "    frames = frames.to(torch.float32)\n",
    "\n",
    "    heatmap_pred = model(frames.unsqueeze(0)).squeeze().numpy()\n",
    "\n",
    "    heatmap = heatmap.to(torch.float32).squeeze().numpy()\n",
    "    frames = frames.numpy().transpose(1, 2, 0)\n",
    "\n",
    "frames = [frames[:,:,3*i:3*(i+1)] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h, dpi = 2*640, 2*360, 100\n",
    "fig, axs = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi, nrows=2, ncols=2)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, (frame, ax) in enumerate(zip(frames, axs)):\n",
    "    ax.set_title(f'Frame {i+1}')\n",
    "    ax.imshow(frame)\n",
    "\n",
    "    x = dataset._label_df['x'][i+dataset_element]\n",
    "    y = dataset._label_df['y'][i+dataset_element]\n",
    "    ax.scatter(x*frame.shape[1], y*frame.shape[0], zorder=100, facecolors='none', edgecolors='y', linewidths=3, s=150)\n",
    "\n",
    "axs[3].imshow(heatmap, cmap='gray')\n",
    "axs[3].set_title('Target heatmap')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(os.path.join(figures_folder, 'sample_input_a.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h, dpi = 640, 360, 100\n",
    "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "ax.imshow(frames[-1], cmap='gray')\n",
    "ax.imshow(heatmap, cmap='gray', alpha=0.5)\n",
    "\n",
    "ax.set_axis_off()\n",
    "fig.tight_layout(pad=0)\n",
    "\n",
    "fig.savefig(os.path.join(figures_folder, 'sample_input_b.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from detection.visualization import show_loss_history, get_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_configurations import (regnet_y_400mf, tracknet_v2, tracknet_v2_2f,\n",
    "                                  tracknet_v2_4f, tracknet_v2_6f,\n",
    "                                  tracknet_v2_rnn, tracknet_v2_rnn_scheduler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegNet and Standard architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_configurations = [regnet_y_400mf, tracknet_v2, tracknet_v2_2f, tracknet_v2_6f] #, tracknet_v2_rnn_scheduler]\n",
    "names = ['regnet_y_400mf', 'tracknet_3f', 'tracknet_2f', 'tracknet_6f'] #, 'tracknet_rnn']\n",
    "titles = ['RegNet, $n=3$', 'Standard, $n=3$', 'Standard, $n=2$', 'Standard, $n=6$'] #, 'Recurrent, $n=1$, $h=3$']\n",
    "\n",
    "for training_configuration, name, title in zip(training_configurations, names, titles):\n",
    "    w, h, dpi = 640, 480, 120\n",
    "    fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax = show_loss_history(training_configuration, ax=ax)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout\n",
    "\n",
    "    fig.savefig(os.path.join(figures_folder, f'{name}.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for training_configuration, name in zip(training_configurations, names):\n",
    "    print(name)\n",
    "    print()\n",
    "\n",
    "    train_loss, val_loss = get_loss_history(training_configuration)\n",
    "    df = pd.DataFrame({'epoch': np.arange(len(train_loss))+1, 'train loss': train_loss, 'validation loss': val_loss})\n",
    "    print(df.to_latex(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rnn_history(training_configuration):\n",
    "    phases = np.array([0, 10, 15, 20, 25, 30, 35]) + 0.5\n",
    "\n",
    "    w, h, dpi = 640, 480, 120\n",
    "    fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "    ax = show_loss_history(training_configuration, ax=ax, epoch_range=(1, 35))\n",
    "\n",
    "    xlim = ax.get_xbound()\n",
    "    ylim = ax.get_ybound()\n",
    "\n",
    "    for i, p in enumerate(phases[1:-1]):\n",
    "        ax.plot([p,p], [ylim[0], ylim[1]], 'k--', linewidth=0.5 if i%2==0 else 0.7)\n",
    "\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "    bbox = {'boxstyle': 'round',\n",
    "            'facecolor': 'w',\n",
    "            'edgecolor': 'None',\n",
    "            'alpha': 0.7}\n",
    "\n",
    "    for i, c in enumerate(['r', 'g', 'b']):\n",
    "        t = 0.1\n",
    "        xpos = 10*i+6 if i==0 else 10*i+8\n",
    "        ax.annotate(f'Phase {i+1}', [xpos, t*ylim[1]+(1-t)*ylim[0]], bbox=bbox)\n",
    "        ax.fill_between([phases[2*i], phases[2*(i+1)]], ylim[0], ylim[1], color=c, alpha=0.15)\n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_rnn_history(tracknet_v2_rnn)\n",
    "fig.suptitle('Recurrent, $n=1$, $h=3$, constant lr')\n",
    "fig.savefig(os.path.join(figures_folder, f'tracknet_rnn.pdf'))\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plot_rnn_history(tracknet_v2_rnn_scheduler)\n",
    "fig.suptitle('Recurrent, $n=1$, $h=3$, step lr')\n",
    "fig.savefig(os.path.join(figures_folder, f'tracknet_rnn_scheduler.pdf'))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(training_configuration, training_phase=None):\n",
    "    config = training_configuration.Config()\n",
    "\n",
    "    checkpoint_folder = config._checkpoint_folder\n",
    "    if training_phase is not None:\n",
    "        checkpoint_folder = os.path.join(checkpoint_folder, training_phase)\n",
    "\n",
    "    results_folder = _get_results_folder(checkpoint_folder, None)\n",
    "    checkpoint_path = os.path.join(results_folder, _get_checkpoint_filename(checkpoint_folder))\n",
    "\n",
    "    model = config.get_model()\n",
    "    model.eval()\n",
    "    model.load(checkpoint_path, device='cpu')\n",
    "\n",
    "    return get_standard_test_dataset(training_configuration, 'prova'), model\n",
    "\n",
    "\n",
    "def get_output(model, dataset, i):\n",
    "    frame, _ = dataset[i]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(frame.to(torch.float32).unsqueeze(0)).numpy().squeeze()\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_frame(dataset, i):\n",
    "    frame, _ = dataset[i]\n",
    "\n",
    "    return frame[-3:].to(torch.float32).numpy().transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, model = get_trained_model(tracknet_v2_rnn_scheduler, 'phase_3_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_output(training_configuration, frame_offset):\n",
    "    training_phase = 'phase_3_1' if frame_offset==1 else None\n",
    "    sample = 19 - frame_offset\n",
    "    dataset, model = get_trained_model(training_configuration, training_phase)\n",
    "    frame = get_frame(dataset, sample)\n",
    "    output =  get_output(model, dataset, sample)\n",
    "\n",
    "    w, h, dpi = 640, 480, 120\n",
    "    fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "    ax.imshow(frame)\n",
    "    ax.imshow(output, alpha=0.7, cmap='gray')\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    fig.tight_layout(pad=0)\n",
    "\n",
    "    fig.savefig(os.path.join(figures_folder, f\"tracknet_{frame_offset}f_example.png\"))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "training_configurations = [tracknet_v2_2f, tracknet_v2, tracknet_v2_4f, tracknet_v2_6f, tracknet_v2_rnn, tracknet_v2_rnn_scheduler]\n",
    "\n",
    "n_frames = [2, 3, 4, 6, 1, 1]\n",
    "\n",
    "for n, training_configuration in zip(n_frames, training_configurations):\n",
    "    show_sample_output(training_configuration, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fc0ed74a087944f7d4394f4d91ee1483def030b33d45c86fb544dde79387957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
