{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from utils.dataset import VideoDataset, MyConcatDataset\n",
    "from utils.models import TrackNetV2MSE, TrackNetV2NLL\n",
    "from utils.training import train_model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 3\n",
    "one_output_frame = True\n",
    "\n",
    "image_size = (360, 640)\n",
    "\n",
    "dataset_params = dict(image_size=image_size,\n",
    "                      sigma=5,\n",
    "                      sequence_length=sequence_length,\n",
    "                      heatmap_mode='image',\n",
    "                      one_output_frame=one_output_frame,\n",
    "                      drop_duplicate_frames=True,\n",
    "                      preload_in_memory=True)\n",
    "\n",
    "# add transforms\n",
    "dataset_params['transform'] = ToTensor()\n",
    "dataset_params['target_transform'] = ToTensor()\n",
    "\n",
    "dataset = VideoDataset(root=\"../datasets/prova/\", duplicate_equality_threshold=1, **dataset_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, labels = dataset[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 20\n",
    "\n",
    "st = time.time()\n",
    "for i in range(N):\n",
    "    dataset[i]\n",
    "    print(f\"{i+1} of {N}\", end = '\\r')\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[:3].numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_raise():\n",
    "    raise ValueError()\n",
    "\n",
    "try:\n",
    "    do_raise()\n",
    "    print('a')\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../datasets/prova/video.MP4\")\n",
    "print(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "st = time.time()\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 10)\n",
    "print(time.time() - st)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "st = time.time()\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 100)\n",
    "print(time.time() - st)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "st = time.time()\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 1000)\n",
    "print(time.time() - st)\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "\n",
    "cap = cv2.VideoCapture(\"../datasets/prova/video.MP4\")\n",
    "fc = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "st = time.time()\n",
    "for i in range(N):\n",
    "    i = np.random.randint(0, fc)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"AAA\")\n",
    "cap.release()\n",
    "\n",
    "t1 = time.time() - st\n",
    "print(t1)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"../datasets/prova/video.MP4\")\n",
    "\n",
    "st = time.time()\n",
    "ret = True\n",
    "i=0\n",
    "while ret and i<N:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        i+=1\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        print(f\"Frame {i}\", end = '\\r')\n",
    "    else:\n",
    "        print(f\"Frame {i} (finished)\")\n",
    "cap.release()\n",
    "t2 = time.time() - st\n",
    "print(t2)\n",
    "print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fc0ed74a087944f7d4394f4d91ee1483def030b33d45c86fb544dde79387957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
