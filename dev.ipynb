{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils.dataset import VideoDataset\n",
    "from utils.training import train_model\n",
    "from utils.models import TrackNet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 3\n",
    "\n",
    "dataset_params = dict(root=\"../videos/dataset_finales_2020_en/\", image_size=(256, 256), sigma=5, sequence_length=sequence_length)\n",
    "\n",
    "dataset_demo = VideoDataset(**dataset_params)\n",
    "dataset_train = VideoDataset(**dataset_params, transform=ToTensor(), target_transform=ToTensor(), split='train')\n",
    "dataset_val = VideoDataset(**dataset_params, transform=ToTensor(), target_transform=ToTensor(), split='val')\n",
    "\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=1)\n",
    "data_loader_val = DataLoader(dataset_val, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h, dpi = 480, 853, 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "frames, labels = dataset_demo[66]\n",
    "ax.imshow(frames[0])\n",
    "ax.imshow(labels[0], alpha=0.6, cmap='gray')\n",
    "ax.set_axis_off()\n",
    "fig.tight_layout(pad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrackNet(sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: check the loss function\n",
    "#TODO: check the training recipe\n",
    "\n",
    "train_model(model,\n",
    "            data_loader_train,\n",
    "            data_loader_val,\n",
    "            loss_function=F.mse_loss,\n",
    "            epochs=1,\n",
    "            device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "695c89e8d1a0e3ecb3b35b5172c9b51550f30a782fca086e9907470f1e458eec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
