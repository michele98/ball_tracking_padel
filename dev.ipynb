{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "plt.style.use('default')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from detection.dataset import VideoDataset, MyConcatDataset, VideoDatasetRNN\n",
    "from detection.models import TrackNetV2MSE, TrackNetV2NLL, TrackNetV2RNN\n",
    "from detection.training import train_model\n",
    "from detection.testing import get_local_maxima\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory analysis with RANSAC on heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection.testing import get_local_maxima\n",
    "\n",
    "video_source = '../datasets/dataset_lluis/game5/video.mp4'\n",
    "# heatmaps_folder = './checkpoints/tracknet_v2_rnn_360_640/phase_3_0/checkpoint_0002_results/heatmaps_test_standard'\n",
    "# heatmaps_folder = './checkpoints/tracknet_v2_mse_360_640/checkpoint_0027_results/heatmaps_test_standard'\n",
    "heatmaps_folder = './checkpoints/tracknet_v2_mse_360_640/checkpoint_0027_results/heatmaps_val'\n",
    "detection_df = pd.read_csv('./checkpoints/tracknet_v2_mse_360_640/checkpoint_0027_results/output_val.csv')\n",
    "# detection_df = detection_df.loc[detection_df['dataset_id']==1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(video_source, frame_index, w_frame=1280, h_frame=720):\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index+2)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('Failed to read frame')\n",
    "        return None\n",
    "\n",
    "    return cv2.cvtColor(cv2.resize(frame, (w_frame, h_frame)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def get_heatmap(heatmaps_folder, heatmap_index, w_heatmap=640, h_heatmap=360):\n",
    "    return cv2.imread(os.path.join(heatmaps_folder, f\"{heatmap_index}\".zfill(6)+'.png'), cv2.IMREAD_GRAYSCALE)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_candidates = 20\n",
    "detection_df_part = detection_df[detection_df['dataset_id']==1]\n",
    "\n",
    "candidates = np.zeros((len(detection_df_part), max_num_candidates, 2))  # candidates array\n",
    "n_candidates = np.zeros(len(candidates))\n",
    "\n",
    "for i, df_index in enumerate(detection_df_part.index):\n",
    "    print(f\"{i+1} of {len(detection_df_part)}\", end = '\\r')\n",
    "    # frame_index = detection_df['frame_num'][i]\n",
    "    normalized_heatmap = cv2.imread(os.path.join(heatmaps_folder, f\"{df_index}\".zfill(6)+'.png'), cv2.IMREAD_GRAYSCALE)/255\n",
    "\n",
    "    max_heatmap_value = detection_df['max_values'][df_index]\n",
    "    min_heatmap_value = detection_df['min_values'][df_index]\n",
    "    heatmap = (normalized_heatmap-min_heatmap_value) * (max_heatmap_value-min_heatmap_value)\n",
    "\n",
    "    m = get_local_maxima(heatmap, threshold=0.1, sigma=0.5)\n",
    "\n",
    "    candidates[i, :len(m)] = m[:max_num_candidates]\n",
    "    n_candidates[i] = min(len(m), max_num_candidates)\n",
    "\n",
    "print(f\"{i+1} of {len(detection_df_part)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_seed = 5\n",
    "\n",
    "df_index = detection_df_part.index[k_seed]\n",
    "\n",
    "frame = get_frame(video_source, detection_df_part['frame_num'][detection_df_part.index[k_seed]])\n",
    "heatmap = get_heatmap(heatmaps_folder, detection_df_part.index[k_seed])\n",
    "\n",
    "h_frame, w_frame = frame.shape[:2]\n",
    "\n",
    "frt = frame.shape[0]/heatmap.shape[0]\n",
    "\n",
    "plt.imshow(frame)\n",
    "plt.imshow(cv2.resize(heatmap, (frame.shape[1], frame.shape[0])), cmap='gray', alpha=0.7)\n",
    "plt.scatter(candidates[k_seed][:,1]*frt, candidates[k_seed][:,0]*frt, s=4, c='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit parabolic trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectories.fitting import *\n",
    "from trajectories.filtering import *\n",
    "from trajectories.visualization import *\n",
    "from trajectories.utils import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_info = []\n",
    "\n",
    "info_keys = ['k_seed','k_min','k_mid','k_max','i_seed','i_min','i_mid','i_max','n_support','iterations']\n",
    "\n",
    "display_fit = False\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "for k in range(len(candidates)):\n",
    "    k_seed = k\n",
    "\n",
    "    d_threshold = 5\n",
    "    seed_radius = 20\n",
    "\n",
    "    N = 10\n",
    "\n",
    "    parameters, info, trajectory, supports, cost = fit_trajectory(candidates, n_candidates, k_seed, seed_radius, d_threshold, N)\n",
    "\n",
    "    if cost is None:\n",
    "        if display_fit:\n",
    "            print(f\"Seed frame: {k}\")\n",
    "            plt.imshow(frames[k])\n",
    "            plt.show()\n",
    "        continue\n",
    "\n",
    "    if (parameters == 0).all() or info['n_support'] <= 3:\n",
    "        # exclusion criteria:\n",
    "        # - points\n",
    "        # - support set smaller than 5\n",
    "        continue\n",
    "\n",
    "    if display_fit:\n",
    "        # k_min = supports[s,0,]\n",
    "        print(f\"Seed frame: {info['k_seed']}\")\n",
    "        print(f\"Used frame for fit: {info['k_min']}, {info['k_mid']}, {info['k_max']}\")\n",
    "        print(f\"Used candidate for fit: {info['i_min']}, {info['i_mid']}, {info['i_max']}\")\n",
    "        print(f\"support: {supports}\")\n",
    "        print(f\"cost = {cost}\")\n",
    "        print(f\"Iterations: {info['iterations']}\")\n",
    "        print(f\"v = {parameters[0]}\")\n",
    "        print(f\"a = {parameters[1]}\")\n",
    "        show_fit(trajectory, candidates,\n",
    "                *[info[key] for key in list(info.keys())[:-2]],\n",
    "                background=frames[info['k_min']])\n",
    "        plt.show()\n",
    "\n",
    "    d = {key: info[key] for key in info_keys}\n",
    "    d['v'] = parameters[0]\n",
    "    d['a'] = parameters[1]\n",
    "    d['trajectory'] = trajectory\n",
    "    d['support'] = supports\n",
    "    d['cost'] = cost\n",
    "    trajectory_info.append(d)\n",
    "\n",
    "    print(f\"{k+1} of {len(candidates)}\", end='\\r')\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Execution time: {t1-t}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build trajectory graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(trajectory_info, i):\n",
    "    k_seed = trajectory_info[i]['k_seed']\n",
    "    trajectory = trajectory_info[i]['trajectory']\n",
    "    support = trajectory_info[i]['support']\n",
    "    return trajectory, support, k_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import DiGraph, dijkstra_path\n",
    "import networkx as nx\n",
    "\n",
    "max_diff = N\n",
    "\n",
    "trajectory_graph = DiGraph()\n",
    "\n",
    "for i in range(len(trajectory_info)):\n",
    "    for j in range(i, min(i+max_diff, len(trajectory_info))):\n",
    "        t1, s1, k1 = extract(trajectory_info, i)\n",
    "        t2, s2, k2 = extract(trajectory_info, j)\n",
    "        d = trajectory_distance(t1, s1, k1, t2, s2, k2)\n",
    "\n",
    "        if d != np.inf and i!=j:\n",
    "            trajectory_graph.add_edge(k1, k2, weight=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcc = list(nx.weakly_connected_components(trajectory_graph))\n",
    "shortest_paths = []\n",
    "\n",
    "for el in wcc:\n",
    "    shortest_paths.append(dijkstra_path(trajectory_graph, min(el), max(el)))\n",
    "    # print(sorted(el))\n",
    "print(len(shortest_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in wcc:\n",
    "    print(sorted(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shortest_paths[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = trajectory_graph.subgraph(range(2399, 2419))\n",
    "# G = trajectory_graph.subgraph(range(3, 28))\n",
    "\n",
    "w, h, dpi = 1800, 600, 100\n",
    "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "# Create a linear layout\n",
    "pos = {node: (i, 0) for i, node in enumerate(sorted(G.nodes()))}\n",
    "\n",
    "# Draw the nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=500, linewidths=2)\n",
    "\n",
    "def get_index(G, u):\n",
    "    node_list = list(sorted(G.nodes()))\n",
    "    return node_list.index(u)\n",
    "\n",
    "# Draw the curved edges\n",
    "for u, v, weight in G.edges.data('weight'):\n",
    "    edge_color = 'r' if weight > 0 else 'k'\n",
    "    # d = -0.2 * np.log(v-u)  # Control the curvature of the edges\n",
    "    x = get_index(G, v) - get_index(G, u)\n",
    "    d = -0.5*(1-np.exp(-0.4*(x-1)))  # Control the curvature of the edges\n",
    "    d = d if u%2 == 1 else -d\n",
    "    xs, ys = pos[u]\n",
    "    xt, yt = pos[v]\n",
    "    xc = (xs + xt) / 2\n",
    "    yc = (ys + yt) / 2\n",
    "    xc += d * (yt - ys)\n",
    "    yc += d * (xs - xt)\n",
    "    curve = [(xs, ys), (xc, yc), (xt, yt)]\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=[(u, v)], edge_color=edge_color, width=1, alpha=1, connectionstyle=f'arc3,rad={d}', arrowstyle='-|>', arrowsize=10)\n",
    "\n",
    "# Add labels to the nodes\n",
    "nx.draw_networkx_labels(G, pos, font_color='k')\n",
    "\n",
    "# Set the x-axis limits to include the nodes\n",
    "ax.set_xlim(-0.5, len(G.nodes())-0.5)\n",
    "# Set the y-axis limits\n",
    "ax.set_ylim([-1, 1])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the graph\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize on frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = np.array([t['k_seed'] for t in trajectory_info])\n",
    "\n",
    "dpi = 50\n",
    "fig, ax = plt.subplots(figsize=(w_frame/dpi, h_frame/dpi), dpi=dpi)\n",
    "\n",
    "# colors = ['r', 'g', 'y', 'k']\n",
    "colors = ['y', 'w']\n",
    "\n",
    "ax.imshow(get_frame(video_source, detection_df_part['frame_num'][detection_df_part.index[2402]]), zorder=-2)\n",
    "\n",
    "to_print = []\n",
    "for i, node in enumerate(shortest_paths[0]):\n",
    "    if node not in range(2399, 2419):\n",
    "        continue\n",
    "\n",
    "    to_print.append(node)\n",
    "    df_index = np.where(ti==node)[0][0]\n",
    "    trajectory = trajectory_info[df_index]['trajectory']\n",
    "\n",
    "    k_min = trajectory_info[df_index]['k_min']\n",
    "    try:\n",
    "        next_index = np.where(ti==shortest_paths[0][i+1])[0][0]\n",
    "        k_max = trajectory_info[next_index]['k_min']\n",
    "    except IndexError as e:\n",
    "        k_max = trajectory_info[df_index]['k_max']\n",
    "\n",
    "    show_fit(trajectory*frt, candidates*frt,\n",
    "             k_min=k_min,\n",
    "             k_mid=trajectory_info[df_index]['k_mid'],\n",
    "             k_max=k_max,\n",
    "             i_min=trajectory_info[df_index]['i_min'],\n",
    "             i_mid=trajectory_info[df_index]['i_mid'],\n",
    "             i_max=trajectory_info[df_index]['i_max'],\n",
    "             k_seed=trajectory_info[df_index]['k_seed'],\n",
    "             i_seed=trajectory_info[df_index]['i_seed'],\n",
    "             ax=ax,\n",
    "             annotate=True,\n",
    "             show_fitting_points=True,\n",
    "             trajectory_color=colors[i%len(colors)])# 'y' if i%2==0 else 'r')\n",
    "ax.set_xlim(0, w_frame)\n",
    "ax.set_ylim(h_frame, 0)\n",
    "\n",
    "print(to_print)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = np.array([t['k_seed'] for t in trajectory_info])\n",
    "\n",
    "dpi = 50\n",
    "fig, ax = plt.subplots(figsize=(w_frame/dpi, h_frame/dpi), dpi=dpi)\n",
    "\n",
    "colors = ['r', 'w', 'g', 'k']\n",
    "ax.imshow(get_frame(video_source, detection_df_part['frame_num'][detection_df_part.index[99]]), zorder=-2)\n",
    "\n",
    "# for i, frame in enumerate((107, 115, 123)):\n",
    "for i, frame in enumerate((100, 101)):\n",
    "# for i, frame in enumerate((77,)):\n",
    "    df_index = np.where(ti==frame)[0][0]\n",
    "    trajectory = trajectory_info[df_index]['trajectory']\n",
    "\n",
    "\n",
    "    show_fit(trajectory*frt, candidates*frt, *[trajectory_info[df_index][key] for key in info_keys[:-2]],\n",
    "             ax=ax,\n",
    "             annotate=True,\n",
    "             show_fitting_points=True,\n",
    "             trajectory_color=colors[i%len(colors)])# 'y' if i%2==0 else 'r')\n",
    "    ax.set_xlim(0, w_frame)\n",
    "    ax.set_ylim(h_frame, 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some activations and kernels because why not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrackNetV2RNN(sequence_length=4)\n",
    "model.load('checkpoints/tracknet_v2_rnn_360_640/phase_3_0/checkpoint_0002_best.ckpt')\n",
    "model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = dict(image_size=(360, 640),\n",
    "                      sequence_length=4,\n",
    "                      sigma=5,\n",
    "                      drop_duplicate_frames=False,\n",
    "                      transform = ToTensor(),\n",
    "                      target_transform = ToTensor(),\n",
    "                      grayscale=False)\n",
    "\n",
    "dataset = VideoDatasetRNN(root=\"../datasets/prova/\", **dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "def get_encoding_layer(desired_block=1, subblock=0):\n",
    "    layers = []\n",
    "    for i, block in enumerate(model.children()):\n",
    "        # print(i)\n",
    "        if i%2 == 1:\n",
    "            layers.append(block)\n",
    "        for j, block_element in enumerate(block.children()):\n",
    "            #print(i, j)\n",
    "            for k, layer in enumerate(block_element.children()):\n",
    "                layers.append(layer)\n",
    "                # print(i, j, k)\n",
    "                if type(layer) is torch.nn.ReLU and i==2*desired_block and j==subblock:\n",
    "                    break\n",
    "            if type(layer) is torch.nn.ReLU and i==2*desired_block and j==subblock:\n",
    "                break\n",
    "        if type(layer) is torch.nn.ReLU and i==2*desired_block:\n",
    "            break\n",
    "    return layers\n",
    "\n",
    "def compute_activations(layers, input):\n",
    "    activation = input.unsqueeze(dim=0)\n",
    "    with torch.no_grad():\n",
    "        for l in layers:\n",
    "            activation = l(activation)\n",
    "\n",
    "    return activation.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, labels = dataset[50]\n",
    "frames = frames.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h_frame, dpi = 300*2*16/9, 300, 100\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(w/dpi, h_frame/dpi), dpi=dpi)\n",
    "\n",
    "axs[0].imshow(frames[-3:].numpy().transpose(1, 2, 0))\n",
    "axs[0].set_title(\"Input frame (last in sequence)\")\n",
    "\n",
    "axs[1].imshow(labels[0])\n",
    "axs[1].set_title(\"Ground truth\")\n",
    "\n",
    "fig.tight_layout(pad=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_part = np.linspace(0, 1, 10)\n",
    "c = []\n",
    "\n",
    "for n in noise_part:\n",
    "    with torch.no_grad():\n",
    "        f = (1-n)*frames + n*torch.randn(frames.shape)\n",
    "        out = model(f.unsqueeze(dim=0)).squeeze().numpy()\n",
    "    c.append(out.max())\n",
    "plt.plot(noise_part, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0.07\n",
    "with torch.no_grad():\n",
    "    f = (1-n)*frames + n*torch.randn(frames.shape)\n",
    "    out = model(f.unsqueeze(dim=0)).squeeze().numpy()\n",
    "plt.imshow(out)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[:3] = torch.zeros(3, 360, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = 2\n",
    "subblock = 1\n",
    "\n",
    "activations = compute_activations(get_encoding_layer(block, subblock), frames)\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dead_activations, ) = np.where(activations.max(axis=(1,2))==0)\n",
    "print(f\"Of {activations.shape[0]} activations, {dead_activations.size} are dead and {activations.shape[0]-dead_activations.size} are not.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_pixels = 1080\n",
    "top_adjust = 1\n",
    "\n",
    "w, h_frame, dpi = height_pixels*16/9*top_adjust, height_pixels, 100\n",
    "fig, axs = plt.subplots(nrows=8, ncols=8, figsize=(w/dpi, h_frame/dpi), dpi=dpi)\n",
    "\n",
    "i_0 = 0\n",
    "\n",
    "for k, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(activations[k+i_0], cmap='gray')\n",
    "    # ax.set_title(i)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "#fig.suptitle(f\"Activations in encoding block {block}, subblock {subblock}\")\n",
    "\n",
    "fig.tight_layout(pad=0.5)\n",
    "fig.subplots_adjust(top=top_adjust)\n",
    "\n",
    "#fig.savefig(f\"{block}_{subblock}.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = 4\n",
    "\n",
    "kernels = model.state_dict()['vgg_conv1.1.0.weight'].numpy()\n",
    "biases = model.state_dict()['vgg_conv1.1.0.bias'].numpy()\n",
    "w, h_frame, dpi = 800, 800, 100\n",
    "fig, axs = plt.subplots(nrows=8, ncols=8, figsize=(w/dpi, h_frame/dpi), dpi=dpi)\n",
    "\n",
    "print(kernels.shape)\n",
    "print(biases[dk])\n",
    "\n",
    "min_val = kernels[dk].min()\n",
    "max_val = kernels[dk].max()\n",
    "print(min_val, max_val)\n",
    "\n",
    "max_val=max((max_val, -min_val))\n",
    "min_val=min((-max_val, min_val))\n",
    "\n",
    "for k, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(kernels[dk,k], cmap='RdBu', vmin=min_val, vmax=max_val)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "#fig.suptitle(f\"Kernel {k}, bias = {biases[k]:.2g}\")\n",
    "fig.tight_layout(pad=0.2)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fc0ed74a087944f7d4394f4d91ee1483def030b33d45c86fb544dde79387957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
