{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from detection.testing import _get_checkpoint_filename, _get_results_folder\n",
    "from detection.visualization import show_loss_history\n",
    "\n",
    "from train_configurations.utils import get_standard_test_dataset\n",
    "from train_configurations import (regnet_y_400mf, regnet_y_800mf,\n",
    "                                  tracknet_v2, tracknet_v2_2f,\n",
    "                                  tracknet_v2_4f, tracknet_v2_6f,\n",
    "                                  tracknet_v2_rnn, tracknet_v2_rnn_scheduler)\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "figures_folder = '../TFM/pictures'\n",
    "# figures_folder = \"C:/Users/calva/Documents/Uni/Master AI/Tesi/TFM/pictures\"\n",
    "\n",
    "if not os.path.exists(figures_folder):\n",
    "    os.makedirs(figures_folder)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# sequence of train configurations\n",
    "training_configurations = [regnet_y_400mf, regnet_y_800mf,\n",
    "                           tracknet_v2_2f, tracknet_v2,\n",
    "                           tracknet_v2_4f, tracknet_v2_6f,\n",
    "                           tracknet_v2_rnn, tracknet_v2_rnn_scheduler]\n",
    "\n",
    "\n",
    "# get the name of the train configuration as string\n",
    "def tc_name(training_configuration):\n",
    "    \"\"\"Return the name of the train configuration as string\"\"\"\n",
    "    name = training_configuration.__name__.split('.')[-1]\n",
    "    if name == 'tracknet_v2':\n",
    "        name = 'tracknet_v2_3f'\n",
    "    return name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectures and train configuration explanations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table for the architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "n = [3, 3, 2, 3, 4, 6, 1, 1]\n",
    "h = [0, 0, 0, 0, 0, 0, 3, 3]\n",
    "epochs = [40, 40, 20, 42, 23, 20, 35, 35]\n",
    "batch_size = [16, 16, 8, 8, 8, 8, 8, 8]\n",
    "for i, tc in enumerate(training_configurations):\n",
    "    d = {'configuration': tc_name(tc),\n",
    "         'n': n[i],\n",
    "         'h': h[i],\n",
    "         'epochs': epochs[i],\n",
    "         'batch size': batch_size[i]\n",
    "         }\n",
    "    table.append(d)\n",
    "\n",
    "df = pd.DataFrame(table)\n",
    "display(df)\n",
    "print(df.to_latex(index=False))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define some utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(training_configuration, training_phase=None):\n",
    "    \"\"\"Get the model of the provided train configuration with the final weights.\"\"\"\n",
    "    config = training_configuration.Config()\n",
    "\n",
    "    checkpoint_folder = config._checkpoint_folder\n",
    "    if training_phase is not None:\n",
    "        checkpoint_folder = os.path.join(checkpoint_folder, training_phase)\n",
    "\n",
    "    results_folder = _get_results_folder(checkpoint_folder, None)\n",
    "    checkpoint_path = os.path.join(results_folder, _get_checkpoint_filename(checkpoint_folder))\n",
    "\n",
    "    model = config.get_model()\n",
    "    model.eval()\n",
    "    model.load(checkpoint_path, device='cpu')\n",
    "\n",
    "    return get_standard_test_dataset(training_configuration, 'prova', is_rnn=training_phase is not None), model\n",
    "\n",
    "\n",
    "def get_output(model, dataset, i):\n",
    "    \"\"\"Get the model output for the given dataset element.\"\"\"\n",
    "    frame, _ = dataset[i]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(frame.to(torch.float32).unsqueeze(0)).numpy().squeeze()\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_frame(dataset, i):\n",
    "    \"\"\"Get the last input frame of the given dataset element element.\"\"\"\n",
    "    frame, _ = dataset[i]\n",
    "    return frame[-3:].to(torch.float32).numpy().transpose(1, 2, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualize an example of input frames and target heatmap. In this example, we will use the ``tracknet_v2_2f`` training configuration.\n",
    "\n",
    "In addition, the model output is also shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from the desired train configuration\n",
    "dataset, model = get_trained_model(tracknet_v2_2f)\n",
    "\n",
    "dataset_element = 15\n",
    "frames, heatmap = dataset[dataset_element]\n",
    "\n",
    "frames = frames.to(torch.float32)\n",
    "frames = frames.numpy().transpose(1, 2, 0)\n",
    "frames = [frames[:,:,3*i:3*(i+1)] for i in range(2)]\n",
    "\n",
    "heatmap = heatmap.to(torch.float32).squeeze().numpy()\n",
    "\n",
    "heatmap_pred = get_output(model, dataset, dataset_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h, dpi = 2*640, 2*360, 100\n",
    "fig, axs = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi, nrows=2, ncols=2)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, (frame, ax) in enumerate(zip(frames, axs)):\n",
    "    ax.set_title(f'Frame {i+1}')\n",
    "    ax.imshow(frame)\n",
    "\n",
    "    x = dataset._label_df['x'][i+dataset_element]\n",
    "    y = dataset._label_df['y'][i+dataset_element]\n",
    "    ax.scatter(x*frame.shape[1], y*frame.shape[0], zorder=100, facecolors='none', edgecolors='y', linewidths=3, s=150)\n",
    "\n",
    "axs[2].imshow(frames[-1])\n",
    "axs[2].imshow(heatmap, alpha=0.7, cmap='gray', vmin=0, vmax=1)\n",
    "axs[2].set_title('Target heatmap')\n",
    "\n",
    "axs[3].imshow(frames[-1])\n",
    "axs[3].imshow(heatmap_pred, alpha=0.7, cmap='gray', vmin=0, vmax=1)\n",
    "axs[3].set_title('Predicted heatmap')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(os.path.join(figures_folder, 'sample_input_a.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output for all models\n",
    "\n",
    "Here we visualize the output of all the various models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the output heatmap for the various tracknet variants superimposed on the last frame of the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tc in training_configurations[2:]:\n",
    "    print(tc_name(tc))\n",
    "    sample = 18\n",
    "    if 'rnn' in tc_name(tc):\n",
    "        training_phase = 'phase_3_0'\n",
    "    else:\n",
    "        training_phase = None\n",
    "        sl = tc.Config()._sequence_length\n",
    "        sample -= sl\n",
    "\n",
    "    dataset, model = get_trained_model(tc, training_phase)\n",
    "    frame = get_frame(dataset, sample)\n",
    "    output =  get_output(model, dataset, sample)\n",
    "\n",
    "    w, h, dpi = 640, 360, 120\n",
    "    fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "    ax.imshow(frame)\n",
    "    ax.imshow(output, alpha=0.7, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    fig.tight_layout(pad=0)\n",
    "\n",
    "    fig.savefig(os.path.join(figures_folder, f\"{tc_name(tc)}_example.png\"))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regnet and Standard configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tc in training_configurations[:-2]:\n",
    "    w, h, dpi = 640, 360, 130\n",
    "    fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax = show_loss_history(tc, ax=ax)\n",
    "\n",
    "    ax.set_title(tc_name(tc))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(figures_folder, f'{tc_name(tc)}_loss.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tc in training_configurations[-2:]:\n",
    "    phases = np.array([0, 10, 15, 20, 25, 30, 35]) + 0.5\n",
    "\n",
    "    w, h, dpi = 640, 360, 130\n",
    "    fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "    ax = show_loss_history(tc, ax=ax, epoch_range=(1, 35))\n",
    "\n",
    "    xlim = ax.get_xbound()\n",
    "    ylim = ax.get_ybound()\n",
    "\n",
    "    for i, p in enumerate(phases[1:-1]):\n",
    "        ax.plot([p,p], [ylim[0], ylim[1]], 'k--', linewidth=0.5 if i%2==0 else 0.7)\n",
    "\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "    bbox = {'boxstyle': 'round',\n",
    "            'facecolor': 'w',\n",
    "            'edgecolor': 'None',\n",
    "            'alpha': 1}\n",
    "\n",
    "    for i, c in enumerate(['r', 'g', 'b']):\n",
    "        t = 0.08\n",
    "        xpos = 10*i+6 if i==0 else 10*i+8\n",
    "        ax.annotate(f'Phase {i+1}', [xpos, t*ylim[1]+(1-t)*ylim[0]], bbox=bbox)\n",
    "        ax.fill_between([phases[2*i], phases[2*(i+1)]], ylim[0], ylim[1], color=c, alpha=0.15)\n",
    "\n",
    "    ax.legend(loc='upper right', framealpha=1)\n",
    "    ax.set_title(tc_name(tc))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(figures_folder, f'{tc_name(tc)}_loss.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results\n",
    "\n",
    "Compute the position error from the csv outputted from model testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the utility function ``get_output_df`` to get a dataframe from the csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_df(training_configuration, training_phase=None):\n",
    "    config = training_configuration.Config()\n",
    "\n",
    "    checkpoint_folder = config._checkpoint_folder\n",
    "    if training_phase is not None:\n",
    "        checkpoint_folder = os.path.join(checkpoint_folder, training_phase)\n",
    "\n",
    "    results_folder = _get_results_folder(checkpoint_folder, None)\n",
    "    return pd.read_csv(os.path.join(results_folder, 'output_val.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dataframe for each train configuration. Take the last training phase for the RNN variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = []\n",
    "for tc in training_configurations:\n",
    "    phase = 'phase_3_0' if 'rnn' in tc_name(tc) else None\n",
    "    df_out.append(get_output_df(tc, phase))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the position error as the magnitude of the difference between the true position and the estimated position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (360, 640)\n",
    "\n",
    "for df in df_out:\n",
    "    x_true, x_pred, y_true, y_pred = [df[k].values for k in ['x_true', 'x_pred', 'y_true', 'y_pred']]\n",
    "    error = (np.sqrt((image_size[1] * (x_true-x_pred))**2 + (image_size[0] * (y_true-y_pred))**2))\n",
    "    df['error'] = error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error histograms\n",
    "\n",
    "Here we visualize the error distributions for the various models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary dataframe with most important statistics of the error:\n",
    " - mean\n",
    " - standard deviation\n",
    " - median\n",
    " - percentage with error < 1 px\n",
    " - percentage with error < 5 px\n",
    " - percentage with error < 10 px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [1, 5, 10] #error strictly smaller than the threshold\n",
    "\n",
    "summary = []\n",
    "for tc, df in zip(training_configurations, df_out):\n",
    "    result = {'train_configuration': tc_name(tc),\n",
    "              'mean': np.mean(df['error']),\n",
    "              'std': np.std(df['error']),\n",
    "              'median': np.median(df['error'])}\n",
    "\n",
    "    hist, bins = np.histogram(df['error'], bins=np.arange(np.max(df['error'])), density=True)\n",
    "    for t in thresholds:\n",
    "        result[f'{t} px'] = hist[:t].sum()\n",
    "\n",
    "    summary.append(result)\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2 = df_summary.copy()\n",
    "for k in df_s2.columns:\n",
    "    if 'px' in k:\n",
    "        df_s2[k] *= 100\n",
    "    else:\n",
    "        def to_apply(x):\n",
    "            if type(x) is float:\n",
    "                return f'{x:.3g}'\n",
    "            else:\n",
    "                return x\n",
    "        df_s2[k] = df_s2[k].apply(to_apply)\n",
    "\n",
    "print(df_s2.to_latex(index=False, float_format=lambda x: f'{x:.2f}'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize error distribution histograms (one ifigure per configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(summary: dict):\n",
    "    for k, v in summary.items():\n",
    "        print_v = v\n",
    "        if 'px' in k:\n",
    "            print_v = f'{100*v:.2g}%'\n",
    "        elif k!='train_configuration':\n",
    "            print_v = f'{v:.2g}'\n",
    "        print(f\"{k}: {print_v}\")\n",
    "\n",
    "\n",
    "hist_range = thresholds[-1]\n",
    "\n",
    "for tc, df, s in zip(training_configurations, df_out, summary):\n",
    "    print_summary(s)\n",
    "\n",
    "    w, h, dpi = 640, 480, 120\n",
    "    fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "    ax.hist(df['error'].clip(upper=hist_range), bins=np.arange(hist_range+2), density=True, align='left', rwidth=0.8)\n",
    "\n",
    "    # legend\n",
    "    for k in [k for k in s.keys() if 'px' in k]:\n",
    "        ax.plot([], [], ' ', label='error < ' + f'{k}:'.rjust(6) + f'{100*s[k]:.1f}%'.rjust(6) + ' ')\n",
    "\n",
    "    for k in ['median', 'mean', 'std']:\n",
    "        ax.plot([], [], ' ', label=f'{k}:'.ljust(14) + f'{s[k]:.1f}'.rjust(5) + ' ')\n",
    "\n",
    "    ax.legend(handlelength=0, prop={'family': 'monospace'}, loc='upper center')\n",
    "\n",
    "    # set title and axis labels\n",
    "    ax.set_title(tc_name(tc))\n",
    "    ax.set_xlabel('Error magnitude')\n",
    "    ax.set_ylabel('Occurrence')\n",
    "\n",
    "    # set axis limits\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(figures_folder, f'{tc_name(tc)}_error.pdf'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize error distribution histograms (all in one figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_range = thresholds[-1]\n",
    "\n",
    "w, h, dpi = 1200, 600, 100\n",
    "fig, axs = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi, nrows=2, ncols=4)\n",
    "\n",
    "axs = axs.T.ravel()\n",
    "\n",
    "for i, (tc, df, s, ax) in enumerate(zip(training_configurations, df_out, summary, axs)):\n",
    "    ax.hist(df['error'].clip(upper=hist_range), bins=np.arange(hist_range+2), density=True, align='left', rwidth=0.8)\n",
    "\n",
    "    # legend\n",
    "    for k in [k for k in s.keys() if 'px' in k]:\n",
    "        ax.plot([], [], ' ', label='error < ' + f'{k}:'.rjust(6) + f'{100*s[k]:.1f}%'.rjust(6) + ' ')\n",
    "\n",
    "    for k in ['median', 'mean', 'std']:\n",
    "        ax.plot([], [], ' ', label=f'{k}:'.ljust(14) + f'{s[k]:.1f}'.rjust(5) + ' ')\n",
    "\n",
    "    ax.legend(handlelength=0, prop={'family': 'monospace'}, loc='upper center')\n",
    "\n",
    "    # set title and axis labels\n",
    "    ax.set_title(tc_name(tc))\n",
    "    if i<2:\n",
    "        ax.set_ylabel('Occurrence')\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    if i%2==1:\n",
    "        ax.set_xlabel('Error magnitude')\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # set axis limits\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(figures_folder, f'errors.pdf'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error as function of maximum heatmap value\n",
    "\n",
    "Here we do a scatterplot of the error and the maximum heatmap value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def linear(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "def quadratic(x, a, b, c):\n",
    "    return a*x*x + b*x + c\n",
    "\n",
    "for tc, df in zip(training_configurations[2:], df_out[2:]):\n",
    "    w, h, dpi = 640, 360, 120\n",
    "    fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "    # sns.histplot(x=df['max_values'], y=df['error'], bins=(np.linspace(0, 1, 50), np.arange(15)), ax=ax, cbar=True)\n",
    "    ax.scatter(x=df['max_values'], y=df['error'], alpha=0.5)\n",
    "\n",
    "    idx = df['max_values'] > 0.2\n",
    "    if idx.values.sum() > 0:\n",
    "        params, cov = curve_fit(linear, df['max_values'][idx], df['error'][idx])\n",
    "        x = np.linspace(0, 1, 2)\n",
    "        plt.plot(x, linear(x, *params), 'k-')\n",
    "\n",
    "        params, cov = curve_fit(quadratic, df['max_values'][idx], df['error'][idx])\n",
    "        x = np.linspace(0, 1, 101)\n",
    "        plt.plot(x, quadratic(x, *params), 'r-')\n",
    "\n",
    "    ax.set_xlabel('max heatmap value')\n",
    "    ax.set_ylabel('position error')\n",
    "\n",
    "    ax.set_xlim(-0.05, 1.05)\n",
    "    ax.set_title(tc_name(tc))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectories fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectories.data_reading import get_candidates, get_frame, get_heatmap\n",
    "\n",
    "from trajectories.fitting import fit_trajectories\n",
    "from trajectories.filtering import build_trajectory_graph, find_shortest_paths, build_path_mapping\n",
    "from trajectories.visualization import create_trajectory_video, visualize_trajectory_graph, show_neighboring_trajectories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory graph example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_frame, candidates, n_candidates, values = get_candidates(tracknet_v2)\n",
    "frame_sequence = list(range(starting_frame, starting_frame + len(candidates)))\n",
    "\n",
    "fitting_info = fit_trajectories(candidates, n_candidates, starting_frame)\n",
    "trajectory_graph = build_trajectory_graph(fitting_info)\n",
    "shortest_paths = find_shortest_paths(trajectory_graph)\n",
    "path_mapping = build_path_mapping(fitting_info, shortest_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize_trajectory_graph(trajectory_graph, shortest_paths[0][0], 889)\n",
    "fig = ax.figure\n",
    "fig.savefig(f'graph_example.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "dpi = 150\n",
    "dark_mode = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big examples for success and failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# success example\n",
    "\n",
    "sf = 995\n",
    "num_prev = 4\n",
    "num_next = 3\n",
    "filename = f'trajectories/example.png'\n",
    "fig, ax = create_trajectory_video(tracknet_v2, os.path.join(figures_folder, filename),\n",
    "                                  fitting_info=fitting_info, path_mapping=path_mapping,\n",
    "                                  starting_frame=sf,\n",
    "                                  dark_mode=dark_mode, dpi=dpi,\n",
    "                                  num_prev=num_prev, num_next=num_next,\n",
    "                                  num_frames=0)\n",
    "plt.close(fig)\n",
    "\n",
    "# fail example\n",
    "sf = 1501\n",
    "num_prev=2\n",
    "num_next=3\n",
    "\n",
    "filename = f'trajectories/example_fail.png'\n",
    "fig, ax = create_trajectory_video(tracknet_v2, os.path.join(figures_folder, filename),\n",
    "                                  fitting_info=fitting_info, path_mapping=path_mapping,\n",
    "                                  starting_frame=sf,\n",
    "                                  dark_mode=dark_mode, dpi=dpi,\n",
    "                                  num_prev=num_prev, num_next=num_next,\n",
    "                                  num_frames=0)\n",
    "plt.close(fig)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shot example (near team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sf in [982, 990, 991, 995]:\n",
    "    if sf<=990:\n",
    "        num_prev = 3\n",
    "        num_next = 4\n",
    "    else:\n",
    "        num_prev = 4\n",
    "        num_next = 3\n",
    "    filename = f'trajectories/{sf}.png'\n",
    "    fig, ax = create_trajectory_video(tracknet_v2, os.path.join(figures_folder, filename),\n",
    "                                      fitting_info=fitting_info, path_mapping=path_mapping,\n",
    "                                      starting_frame=sf,\n",
    "                                      dark_mode=dark_mode, dpi=dpi,\n",
    "                                      num_prev=num_prev, num_next=num_next,\n",
    "                                      num_frames=0)\n",
    "    plt.close(fig)\n",
    "    clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounce example (floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sf in [1005, 1006, 1015]:\n",
    "    if sf<=1005:\n",
    "        num_prev = 3\n",
    "        num_next = 4\n",
    "    else:\n",
    "        num_prev = 4\n",
    "        num_next = 3\n",
    "    filename = f'trajectories/{sf}.png'\n",
    "    fig, ax = create_trajectory_video(tracknet_v2, os.path.join(figures_folder, filename),\n",
    "                                      fitting_info=fitting_info, path_mapping=path_mapping,\n",
    "                                      starting_frame=sf,\n",
    "                                      dark_mode=dark_mode, dpi=dpi,\n",
    "                                      num_prev=num_prev, num_next=num_next,\n",
    "                                      num_frames=0)\n",
    "    plt.close(fig)\n",
    "    clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shot example (far team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sf in [1023, 1024]:\n",
    "    if sf<=1005:\n",
    "        num_prev = 3\n",
    "        num_next = 4\n",
    "    else:\n",
    "        num_prev = 4\n",
    "        num_next = 3\n",
    "    filename = f'trajectories/{sf}.png'\n",
    "    fig, ax = create_trajectory_video(tracknet_v2, os.path.join(figures_folder, filename),\n",
    "                                      fitting_info=fitting_info, path_mapping=path_mapping,\n",
    "                                      starting_frame=sf,\n",
    "                                      dark_mode=dark_mode, dpi=dpi,\n",
    "                                      num_prev=num_prev, num_next=num_next,\n",
    "                                      num_frames=0)\n",
    "    plt.close(fig)\n",
    "    clear_output()\n",
    "\n",
    "for sf in [1537, 1546, 1548, 1554]:\n",
    "    if sf<=1546:\n",
    "        num_next = 4\n",
    "        if sf==1537:\n",
    "            num_prev = 2\n",
    "        else:\n",
    "            num_prev = 3\n",
    "    else:\n",
    "        num_prev = 4\n",
    "        num_next = 3\n",
    "    filename = f'trajectories/{sf}.png'\n",
    "    fig, ax = create_trajectory_video(tracknet_v2, os.path.join(figures_folder, filename),\n",
    "                                      fitting_info=fitting_info, path_mapping=path_mapping,\n",
    "                                      starting_frame=sf,\n",
    "                                      dark_mode=dark_mode, dpi=dpi,\n",
    "                                      num_prev=num_prev, num_next=num_next,\n",
    "                                      num_frames=0)\n",
    "    plt.close(fig)\n",
    "    clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failure example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sf in [1494, 1495, 1498, 1500, 1501]:\n",
    "    filename = f'trajectories/fail_{sf}.png'\n",
    "\n",
    "    display='k_min k_max params'\n",
    "    num_next=3\n",
    "    num_prev=2\n",
    "    if sf == 1494:\n",
    "        display='k_min params'\n",
    "        display_prev = None\n",
    "        num_next=4\n",
    "        num_prev=1\n",
    "    else:\n",
    "        display_prev = 'k_max'\n",
    "\n",
    "    fig, ax = create_trajectory_video(tracknet_v2, os.path.join(figures_folder, filename),\n",
    "                                      fitting_info=fitting_info, path_mapping=path_mapping,\n",
    "                                      starting_frame=sf,\n",
    "                                      dark_mode=dark_mode, dpi=dpi,\n",
    "                                      num_next=num_next, num_prev=num_prev,\n",
    "                                      alpha_prev=1, alpha_next=1,\n",
    "                                      display=display, display_prev=display_prev, display_next='k_min',\n",
    "                                      show_outside_range=True,\n",
    "                                      num_frames=0)\n",
    "    clear_output()\n",
    "    # plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "695c89e8d1a0e3ecb3b35b5172c9b51550f30a782fca086e9907470f1e458eec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
